La musica di <i>bestiary for a microcosm</i> viene generata in tempo reale grazie all'interazione del musicista-performer con un software ideato appositamente, creato nell'ambiente di sviluppo max/MSP. Il codice sfrutta tanto il linguaggio nativo di visual programming di max/MSP che l'object oriented scripting language javascript. L'interazione avviene per mezzo di un'interfaccia Uomo-Macchina composta sia da un output visivo su schermo (essenziale per l'esecuzione) che da due controller hardware (un Apple iPad Pro e un Akai APC40 MkII). 

<br><br>L'intera genesi sonora sfrutta un campo tridimensionale virtuale di forze fisiche, in cui possono prendere vita un numero variabile di 'entità sonore', che, popolando questo spazio e influenzandosi a vicenda, ne compongono continuamente il paesaggio sonoro. Questo campo di forze, che rappresenta virtualmente lo spazio d'ascolto in cui è immerso il pubblico, viene riprodotto nello spazio reale per mezzo di un sistema di diffusione multicanale. In questo modo, il pubblico partecipa agli scambi di forze e alle reciproche interferenze tra le 'entità sonore' virtuali che popolano il campo, condividendone in uno spazio reale, tangibile, i percorsi di vita.

<br><br>L'output visivo di questo spazio virtuale viene inoltre proiettato sulle pareti della sala che accoglie il pubblico, offrendo un secondo livello di comprensione dei processi algoritmici di composizione e spazializzazione dei suoni. Questo output digitale si integra con le immagini analogiche fluide create da Stefano Giorgi in tempo reale, che di questo spazio virtuale sembra tratteggiarne l'anima, cogliendone i desideri e le speranze di realtà. 


